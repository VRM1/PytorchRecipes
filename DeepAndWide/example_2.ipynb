{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.preprocessing import WidePreprocessor, TabPreprocessor\n",
    "from pytorch_widedeep.models import Wide, TabMlp, WideDeep\n",
    "from pytorch_widedeep.metrics import Accuracy, F1Score\n",
    "from pytorch_widedeep.datasets import load_adult\n",
    "from torchmetrics import AveragePrecision, AUROC\n",
    "from pytorch_widedeep.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetData:\n",
    "    def __init__(self, path, dset_name, name, missing_perc=0, n_rows=1, n_clms=1):\n",
    "        self.mask = missing_perc\n",
    "        dset_name = dset_name\n",
    "        if self.mask:\n",
    "            self.suffix = 'Missing{}_1'.format(self.mask)\n",
    "        else:\n",
    "            self.suffix = ''\n",
    "        self.label = {'defaultCredit':'default.payment.next.month', 'bank':'y'}[dset_name]\n",
    "        self.path = path\n",
    "        self.dataset = name\n",
    "        self.n_rows, self.n_clms = n_rows, n_clms\n",
    "        self.embedding = name\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        if self.mask:\n",
    "            return self.parse_mask(self._dataset)\n",
    "        else:\n",
    "            return self._dataset\n",
    "    @property\n",
    "    def embedding(self):\n",
    "        return self._embedding\n",
    "    \n",
    "    @embedding.setter\n",
    "    def embedding(self, name):\n",
    "        fil_name = \"{}/embedding.csv\".format(self.path)\n",
    "        if os.path.isfile(fil_name):\n",
    "            self._embedding = pd.read_csv(fil_name)\n",
    "        else:\n",
    "            print(\"embedding dataset does not exist\")\n",
    "    \n",
    "    @data.setter\n",
    "    def dataset(self, name):\n",
    "\n",
    "        fil_name = \"{}/{}{}.csv\".format(self.path, name, self.suffix)\n",
    "        mask_fil_name = \"{}/{}_{}.csv\".format(self.path, name, self.suffix)\n",
    "        if os.path.isfile(fil_name) and not self.mask:\n",
    "            self._dataset = pd.read_csv(fil_name)\n",
    "            self.n_rows, self.n_clms = self._dataset.shape[0], self._dataset.shape[1]\n",
    "        elif self.mask and os.path.isfile(mask_fil_name):\n",
    "            self._dataset = pd.read_csv(mask_fil_name)\n",
    "\n",
    "    def parse_mask(self, df):\n",
    "\n",
    "        df = df.groupby('row')['col'].apply(list)\n",
    "        mask = []\n",
    "        for i in range(self.n_rows):\n",
    "            clm_indices = np.array(df[i] if i in df.index else [])\n",
    "            mask_i = np.ones(self.n_clms, dtype=np.float64)\n",
    "            if len(clm_indices):\n",
    "                np.put(mask_i, clm_indices, np.nan)\n",
    "            mask += [mask_i]\n",
    "\n",
    "        return np.stack(mask, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding dataset does not exist\n",
      "embedding dataset does not exist\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>emb_9</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155910</td>\n",
       "      <td>-0.792147</td>\n",
       "      <td>0.815270</td>\n",
       "      <td>0.683830</td>\n",
       "      <td>1.597049</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>-1.752827</td>\n",
       "      <td>-0.129553</td>\n",
       "      <td>-0.486362</td>\n",
       "      <td>-0.372769</td>\n",
       "      <td>...</td>\n",
       "      <td>-39980.900</td>\n",
       "      <td>-36665.010</td>\n",
       "      <td>-36393.754</td>\n",
       "      <td>1149.0</td>\n",
       "      <td>2140.0</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>3.750000e+03</td>\n",
       "      <td>2.491000e+03</td>\n",
       "      <td>9.785000e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.206568</td>\n",
       "      <td>1.165155</td>\n",
       "      <td>0.505210</td>\n",
       "      <td>-0.219921</td>\n",
       "      <td>-0.382640</td>\n",
       "      <td>-0.888843</td>\n",
       "      <td>1.307427</td>\n",
       "      <td>1.233807</td>\n",
       "      <td>-0.604676</td>\n",
       "      <td>-0.713044</td>\n",
       "      <td>...</td>\n",
       "      <td>85407.100</td>\n",
       "      <td>91113.990</td>\n",
       "      <td>96357.250</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>7027.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>6.000000e+03</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.259755</td>\n",
       "      <td>-1.481801</td>\n",
       "      <td>-0.975531</td>\n",
       "      <td>-1.255872</td>\n",
       "      <td>-0.939124</td>\n",
       "      <td>-0.481430</td>\n",
       "      <td>-0.677546</td>\n",
       "      <td>-1.196710</td>\n",
       "      <td>-1.595688</td>\n",
       "      <td>0.160315</td>\n",
       "      <td>...</td>\n",
       "      <td>-22316.900</td>\n",
       "      <td>-17128.012</td>\n",
       "      <td>-16247.754</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2.970000e+03</td>\n",
       "      <td>1.000000e-20</td>\n",
       "      <td>1.000000e-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.855731</td>\n",
       "      <td>-0.069268</td>\n",
       "      <td>0.471339</td>\n",
       "      <td>0.903956</td>\n",
       "      <td>-0.652457</td>\n",
       "      <td>-1.678368</td>\n",
       "      <td>1.792997</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>0.567137</td>\n",
       "      <td>-0.222312</td>\n",
       "      <td>...</td>\n",
       "      <td>-12988.899</td>\n",
       "      <td>-10260.012</td>\n",
       "      <td>-38323.754</td>\n",
       "      <td>1655.0</td>\n",
       "      <td>1797.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>1.000000e-20</td>\n",
       "      <td>5.610000e+02</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.798088</td>\n",
       "      <td>0.249370</td>\n",
       "      <td>-0.201120</td>\n",
       "      <td>-2.998457</td>\n",
       "      <td>0.388763</td>\n",
       "      <td>-3.267331</td>\n",
       "      <td>0.053656</td>\n",
       "      <td>3.127441</td>\n",
       "      <td>0.268455</td>\n",
       "      <td>-0.324314</td>\n",
       "      <td>...</td>\n",
       "      <td>27453.100</td>\n",
       "      <td>27738.988</td>\n",
       "      <td>30930.246</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4792.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>3.019000e+03</td>\n",
       "      <td>8.010000e+03</td>\n",
       "      <td>7.000000e+03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0  0.155910 -0.792147  0.815270  0.683830  1.597049  0.066575 -1.752827   \n",
       "1  1.206568  1.165155  0.505210 -0.219921 -0.382640 -0.888843  1.307427   \n",
       "2 -0.259755 -1.481801 -0.975531 -1.255872 -0.939124 -0.481430 -0.677546   \n",
       "3  2.855731 -0.069268  0.471339  0.903956 -0.652457 -1.678368  1.792997   \n",
       "4 -0.798088  0.249370 -0.201120 -2.998457  0.388763 -3.267331  0.053656   \n",
       "\n",
       "      emb_7     emb_8     emb_9  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  \\\n",
       "0 -0.129553 -0.486362 -0.372769  ... -39980.900 -36665.010 -36393.754   \n",
       "1  1.233807 -0.604676 -0.713044  ...  85407.100  91113.990  96357.250   \n",
       "2 -1.196710 -1.595688  0.160315  ... -22316.900 -17128.012 -16247.754   \n",
       "3 -0.171269  0.567137 -0.222312  ... -12988.899 -10260.012 -38323.754   \n",
       "4  3.127441  0.268455 -0.324314  ...  27453.100  27738.988  30930.246   \n",
       "\n",
       "   PAY_AMT1  PAY_AMT2  PAY_AMT3      PAY_AMT4      PAY_AMT5      PAY_AMT6  \\\n",
       "0    1149.0    2140.0    3313.0  3.750000e+03  2.491000e+03  9.785000e+03   \n",
       "1    9000.0    7027.0    5000.0  5.000000e+03  6.000000e+03  5.000000e+03   \n",
       "2    2900.0     700.0    1000.0  2.970000e+03  1.000000e-20  1.000000e-20   \n",
       "3    1655.0    1797.0     750.0  1.000000e-20  5.610000e+02  5.000000e+02   \n",
       "4    5000.0    4792.0    3000.0  3.019000e+03  8.010000e+03  7.000000e+03   \n",
       "\n",
       "   default.payment.next.month  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         0.0  \n",
       "3                         0.0  \n",
       "4                         1.0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = 'defaultCredit'\n",
    "model_name = 'iwae'\n",
    "fold = 0\n",
    "PATH_train= \"/media/6TB_Volume/DataRepo/small_datasets/{}/fold{}/train\".format(data_name, fold)\n",
    "PATH_test = \"/media/6TB_Volume/DataRepo/small_datasets/{}/fold{}/test\".format(data_name, fold)\n",
    "\n",
    "original_data = GetData(PATH_train, data_name, 'normalized_data')\n",
    "embedding_data = GetData(\"{}/{}\".format(PATH_train, model_name), data_name, 'normalized_data')\n",
    "label = original_data.label\n",
    "df = original_data.data\n",
    "# df_emb = embedding_data.embedding.drop(label, axis=1)\n",
    "df_emb = embedding_data.embedding\n",
    "df_train = df_emb.merge(df, right_index=True, left_index=True)\n",
    "\n",
    "original_data = GetData(PATH_test, data_name, 'normalized_data')\n",
    "embedding_data = GetData(\"{}/{}\".format(PATH_test, model_name), data_name, 'normalized_data')\n",
    "test_df = original_data.data\n",
    "# df_emb = embedding_data.embedding.drop(label, axis=1)\n",
    "df_emb = embedding_data.embedding\n",
    "df_test = df_emb.merge(test_df, right_index=True, left_index=True)\n",
    "# train_df, test_df = train_test_split(train_df, test_size=0.20, random_state=42)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_clms = [c for c in df_train.columns if 'emb' in c] \n",
    "df_train = df_train[emb_clms + [label]]\n",
    "df_test = df_test[emb_clms + [label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "      <th>emb_5</th>\n",
       "      <th>emb_6</th>\n",
       "      <th>emb_7</th>\n",
       "      <th>emb_8</th>\n",
       "      <th>emb_9</th>\n",
       "      <th>emb_10</th>\n",
       "      <th>emb_11</th>\n",
       "      <th>emb_12</th>\n",
       "      <th>emb_13</th>\n",
       "      <th>emb_14</th>\n",
       "      <th>emb_15</th>\n",
       "      <th>emb_16</th>\n",
       "      <th>emb_17</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.155910</td>\n",
       "      <td>-0.792147</td>\n",
       "      <td>0.815270</td>\n",
       "      <td>0.683830</td>\n",
       "      <td>1.597049</td>\n",
       "      <td>0.066575</td>\n",
       "      <td>-1.752827</td>\n",
       "      <td>-0.129553</td>\n",
       "      <td>-0.486362</td>\n",
       "      <td>-0.372769</td>\n",
       "      <td>1.234549</td>\n",
       "      <td>-0.164982</td>\n",
       "      <td>1.793444</td>\n",
       "      <td>-0.983856</td>\n",
       "      <td>0.770054</td>\n",
       "      <td>-0.125196</td>\n",
       "      <td>0.113545</td>\n",
       "      <td>9.785000e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.206568</td>\n",
       "      <td>1.165155</td>\n",
       "      <td>0.505210</td>\n",
       "      <td>-0.219921</td>\n",
       "      <td>-0.382640</td>\n",
       "      <td>-0.888843</td>\n",
       "      <td>1.307427</td>\n",
       "      <td>1.233807</td>\n",
       "      <td>-0.604676</td>\n",
       "      <td>-0.713044</td>\n",
       "      <td>-0.872184</td>\n",
       "      <td>0.075260</td>\n",
       "      <td>-0.713897</td>\n",
       "      <td>-2.168599</td>\n",
       "      <td>1.256938</td>\n",
       "      <td>0.154856</td>\n",
       "      <td>-1.120642</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.259755</td>\n",
       "      <td>-1.481801</td>\n",
       "      <td>-0.975531</td>\n",
       "      <td>-1.255872</td>\n",
       "      <td>-0.939124</td>\n",
       "      <td>-0.481430</td>\n",
       "      <td>-0.677546</td>\n",
       "      <td>-1.196710</td>\n",
       "      <td>-1.595688</td>\n",
       "      <td>0.160315</td>\n",
       "      <td>-0.939186</td>\n",
       "      <td>-1.357878</td>\n",
       "      <td>0.516169</td>\n",
       "      <td>0.807556</td>\n",
       "      <td>0.543777</td>\n",
       "      <td>0.221466</td>\n",
       "      <td>0.325076</td>\n",
       "      <td>1.000000e-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.855731</td>\n",
       "      <td>-0.069268</td>\n",
       "      <td>0.471339</td>\n",
       "      <td>0.903956</td>\n",
       "      <td>-0.652457</td>\n",
       "      <td>-1.678368</td>\n",
       "      <td>1.792997</td>\n",
       "      <td>-0.171269</td>\n",
       "      <td>0.567137</td>\n",
       "      <td>-0.222312</td>\n",
       "      <td>-0.146323</td>\n",
       "      <td>1.478627</td>\n",
       "      <td>-2.065691</td>\n",
       "      <td>0.547314</td>\n",
       "      <td>0.103294</td>\n",
       "      <td>-1.030028</td>\n",
       "      <td>1.517152</td>\n",
       "      <td>5.000000e+02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.798088</td>\n",
       "      <td>0.249370</td>\n",
       "      <td>-0.201120</td>\n",
       "      <td>-2.998457</td>\n",
       "      <td>0.388763</td>\n",
       "      <td>-3.267331</td>\n",
       "      <td>0.053656</td>\n",
       "      <td>3.127441</td>\n",
       "      <td>0.268455</td>\n",
       "      <td>-0.324314</td>\n",
       "      <td>-2.050466</td>\n",
       "      <td>-1.639803</td>\n",
       "      <td>1.868531</td>\n",
       "      <td>1.112302</td>\n",
       "      <td>-0.342077</td>\n",
       "      <td>0.594306</td>\n",
       "      <td>-0.451871</td>\n",
       "      <td>7.000000e+03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>-0.649161</td>\n",
       "      <td>1.285938</td>\n",
       "      <td>0.937058</td>\n",
       "      <td>-0.256087</td>\n",
       "      <td>1.505907</td>\n",
       "      <td>-0.880287</td>\n",
       "      <td>1.154492</td>\n",
       "      <td>-0.051122</td>\n",
       "      <td>-0.699979</td>\n",
       "      <td>0.098153</td>\n",
       "      <td>-0.220279</td>\n",
       "      <td>0.391320</td>\n",
       "      <td>-0.800312</td>\n",
       "      <td>-0.457954</td>\n",
       "      <td>1.549020</td>\n",
       "      <td>1.593848</td>\n",
       "      <td>1.756585</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>0.252208</td>\n",
       "      <td>-0.802576</td>\n",
       "      <td>0.701671</td>\n",
       "      <td>-2.737878</td>\n",
       "      <td>-0.064953</td>\n",
       "      <td>0.442832</td>\n",
       "      <td>-0.422472</td>\n",
       "      <td>0.109341</td>\n",
       "      <td>1.166730</td>\n",
       "      <td>-1.103604</td>\n",
       "      <td>0.084031</td>\n",
       "      <td>-0.086175</td>\n",
       "      <td>0.352263</td>\n",
       "      <td>-0.191294</td>\n",
       "      <td>0.282429</td>\n",
       "      <td>-1.687678</td>\n",
       "      <td>-1.871025</td>\n",
       "      <td>1.000000e-20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>1.452086</td>\n",
       "      <td>0.301812</td>\n",
       "      <td>-1.002540</td>\n",
       "      <td>-1.313342</td>\n",
       "      <td>-0.132358</td>\n",
       "      <td>-2.539794</td>\n",
       "      <td>-1.700944</td>\n",
       "      <td>0.524563</td>\n",
       "      <td>0.495863</td>\n",
       "      <td>-0.639290</td>\n",
       "      <td>0.110330</td>\n",
       "      <td>0.049934</td>\n",
       "      <td>-0.380157</td>\n",
       "      <td>-1.932958</td>\n",
       "      <td>-0.526710</td>\n",
       "      <td>0.961133</td>\n",
       "      <td>1.810364</td>\n",
       "      <td>1.500000e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>-0.530893</td>\n",
       "      <td>1.929308</td>\n",
       "      <td>-0.305090</td>\n",
       "      <td>-0.397623</td>\n",
       "      <td>-0.174521</td>\n",
       "      <td>-4.370883</td>\n",
       "      <td>-1.303810</td>\n",
       "      <td>-1.426207</td>\n",
       "      <td>-1.309326</td>\n",
       "      <td>0.540767</td>\n",
       "      <td>-1.959934</td>\n",
       "      <td>0.061655</td>\n",
       "      <td>0.487018</td>\n",
       "      <td>0.208397</td>\n",
       "      <td>-0.334907</td>\n",
       "      <td>0.959959</td>\n",
       "      <td>-0.218460</td>\n",
       "      <td>7.000000e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>-0.495180</td>\n",
       "      <td>0.440794</td>\n",
       "      <td>0.574187</td>\n",
       "      <td>2.428522</td>\n",
       "      <td>-1.345686</td>\n",
       "      <td>-0.864693</td>\n",
       "      <td>-0.371181</td>\n",
       "      <td>0.630643</td>\n",
       "      <td>2.036213</td>\n",
       "      <td>0.212941</td>\n",
       "      <td>2.280724</td>\n",
       "      <td>-1.051752</td>\n",
       "      <td>-2.074160</td>\n",
       "      <td>0.083129</td>\n",
       "      <td>0.349898</td>\n",
       "      <td>1.405123</td>\n",
       "      <td>-0.054981</td>\n",
       "      <td>2.267000e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          emb_0     emb_1     emb_2     emb_3     emb_4     emb_5     emb_6  \\\n",
       "0      0.155910 -0.792147  0.815270  0.683830  1.597049  0.066575 -1.752827   \n",
       "1      1.206568  1.165155  0.505210 -0.219921 -0.382640 -0.888843  1.307427   \n",
       "2     -0.259755 -1.481801 -0.975531 -1.255872 -0.939124 -0.481430 -0.677546   \n",
       "3      2.855731 -0.069268  0.471339  0.903956 -0.652457 -1.678368  1.792997   \n",
       "4     -0.798088  0.249370 -0.201120 -2.998457  0.388763 -3.267331  0.053656   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23995 -0.649161  1.285938  0.937058 -0.256087  1.505907 -0.880287  1.154492   \n",
       "23996  0.252208 -0.802576  0.701671 -2.737878 -0.064953  0.442832 -0.422472   \n",
       "23997  1.452086  0.301812 -1.002540 -1.313342 -0.132358 -2.539794 -1.700944   \n",
       "23998 -0.530893  1.929308 -0.305090 -0.397623 -0.174521 -4.370883 -1.303810   \n",
       "23999 -0.495180  0.440794  0.574187  2.428522 -1.345686 -0.864693 -0.371181   \n",
       "\n",
       "          emb_7     emb_8     emb_9    emb_10    emb_11    emb_12    emb_13  \\\n",
       "0     -0.129553 -0.486362 -0.372769  1.234549 -0.164982  1.793444 -0.983856   \n",
       "1      1.233807 -0.604676 -0.713044 -0.872184  0.075260 -0.713897 -2.168599   \n",
       "2     -1.196710 -1.595688  0.160315 -0.939186 -1.357878  0.516169  0.807556   \n",
       "3     -0.171269  0.567137 -0.222312 -0.146323  1.478627 -2.065691  0.547314   \n",
       "4      3.127441  0.268455 -0.324314 -2.050466 -1.639803  1.868531  1.112302   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "23995 -0.051122 -0.699979  0.098153 -0.220279  0.391320 -0.800312 -0.457954   \n",
       "23996  0.109341  1.166730 -1.103604  0.084031 -0.086175  0.352263 -0.191294   \n",
       "23997  0.524563  0.495863 -0.639290  0.110330  0.049934 -0.380157 -1.932958   \n",
       "23998 -1.426207 -1.309326  0.540767 -1.959934  0.061655  0.487018  0.208397   \n",
       "23999  0.630643  2.036213  0.212941  2.280724 -1.051752 -2.074160  0.083129   \n",
       "\n",
       "         emb_14    emb_15    emb_16        emb_17  default.payment.next.month  \n",
       "0      0.770054 -0.125196  0.113545  9.785000e+03                         0.0  \n",
       "1      1.256938  0.154856 -1.120642  5.000000e+03                         0.0  \n",
       "2      0.543777  0.221466  0.325076  1.000000e-20                         0.0  \n",
       "3      0.103294 -1.030028  1.517152  5.000000e+02                         0.0  \n",
       "4     -0.342077  0.594306 -0.451871  7.000000e+03                         1.0  \n",
       "...         ...       ...       ...           ...                         ...  \n",
       "23995  1.549020  1.593848  1.756585  5.000000e+03                         1.0  \n",
       "23996  0.282429 -1.687678 -1.871025  1.000000e-20                         0.0  \n",
       "23997 -0.526710  0.961133  1.810364  1.500000e+03                         0.0  \n",
       "23998 -0.334907  0.959959 -0.218460  7.000000e+03                         0.0  \n",
       "23999  0.349898  1.405123 -0.054981  2.267000e+03                         0.0  \n",
       "\n",
       "[24000 rows x 19 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/media/6TB_Volume/DataRepo/small_datasets/defaultCredit/fold1/train/normalized_data.csv')\n",
    "df_test = pd.read_csv('/media/6TB_Volume/DataRepo/small_datasets/defaultCredit/fold1/test/normalized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 'column set up'\n",
    "wide_cols = [\n",
    "    \"SEX\",\n",
    "    \"EDUCATION\",\n",
    "    \"MARRIAGE\",\n",
    "    \"PAY_0\",\n",
    "    \"PAY_2\",\n",
    "    \"PAY_3\",\n",
    "    \"PAY_4\",\n",
    "    \"PAY_5\",\n",
    "    \"PAY_6\"\n",
    "]\n",
    "\n",
    "cat_embed_cols = [\n",
    "    \"SEX\",\n",
    "    \"EDUCATION\",\n",
    "    \"MARRIAGE\",\n",
    "    \"PAY_0\",\n",
    "    \"PAY_2\",\n",
    "    \"PAY_3\",\n",
    "    \"PAY_4\",\n",
    "    \"PAY_5\",\n",
    "    \"PAY_6\"\n",
    "]\n",
    "continuous_cols = [\"LIMIT_BAL\", \"BILL_AMT1\", \"BILL_AMT1\", \"BILL_AMT2\", \\\n",
    "     \"BILL_AMT3\", \"BILL_AMT4\", \"BILL_AMT5\", \"BILL_AMT6\", 'PAY_AMT1', 'PAY_AMT1',\\\n",
    "        'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6'] + emb_clms\n",
    "target = \"default.payment.next.month\"\n",
    "target = df_train[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = emb_clms\n",
    "target = \"default.payment.next.month\"\n",
    "target = df_train[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_preprocessor = TabPreprocessor(\n",
    "    continuous_cols=continuous_cols  # type: ignore[arg-type]\n",
    ")\n",
    "X_tab = tab_preprocessor.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model\n",
    "tab_mlp = TabMlp(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    continuous_cols=continuous_cols,\n",
    ")\n",
    "model = WideDeep(deeptabular=tab_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vineeth/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/home/vineeth/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "epoch 1: 100%|██████████| 94/94 [00:01<00:00, 89.98it/s, loss=0.504, metrics={'AUROC': 0.6561, 'f1': 0.1241, 'AveragePrecision': 0.3517}] \n",
      "epoch 2: 100%|██████████| 94/94 [00:01<00:00, 90.52it/s, loss=0.475, metrics={'AUROC': 0.7087, 'f1': 0.3083, 'AveragePrecision': 0.4438}] \n",
      "epoch 3: 100%|██████████| 94/94 [00:01<00:00, 92.06it/s, loss=0.472, metrics={'AUROC': 0.7136, 'f1': 0.3165, 'AveragePrecision': 0.4534}] \n",
      "epoch 4: 100%|██████████| 94/94 [00:01<00:00, 92.75it/s, loss=0.469, metrics={'AUROC': 0.7189, 'f1': 0.319, 'AveragePrecision': 0.4559}]  \n",
      "epoch 5: 100%|██████████| 94/94 [00:01<00:00, 93.73it/s, loss=0.469, metrics={'AUROC': 0.7195, 'f1': 0.324, 'AveragePrecision': 0.4598}]  \n",
      "epoch 6: 100%|██████████| 94/94 [00:01<00:00, 91.28it/s, loss=0.467, metrics={'AUROC': 0.7239, 'f1': 0.3309, 'AveragePrecision': 0.4616}] \n",
      "epoch 7: 100%|██████████| 94/94 [00:01<00:00, 90.32it/s, loss=0.466, metrics={'AUROC': 0.7251, 'f1': 0.3306, 'AveragePrecision': 0.4648}] \n",
      "epoch 8: 100%|██████████| 94/94 [00:01<00:00, 92.90it/s, loss=0.464, metrics={'AUROC': 0.7295, 'f1': 0.3392, 'AveragePrecision': 0.4687}] \n",
      "epoch 9: 100%|██████████| 94/94 [00:01<00:00, 92.10it/s, loss=0.464, metrics={'AUROC': 0.727, 'f1': 0.3481, 'AveragePrecision': 0.4692}]  \n",
      "epoch 10: 100%|██████████| 94/94 [00:01<00:00, 91.04it/s, loss=0.463, metrics={'AUROC': 0.7298, 'f1': 0.3465, 'AveragePrecision': 0.4738}] \n",
      "epoch 11: 100%|██████████| 94/94 [00:01<00:00, 92.14it/s, loss=0.462, metrics={'AUROC': 0.7325, 'f1': 0.3455, 'AveragePrecision': 0.4742}] \n",
      "epoch 12: 100%|██████████| 94/94 [00:00<00:00, 94.22it/s, loss=0.461, metrics={'AUROC': 0.7341, 'f1': 0.3438, 'AveragePrecision': 0.476}]  \n",
      "epoch 13: 100%|██████████| 94/94 [00:01<00:00, 90.44it/s, loss=0.46, metrics={'AUROC': 0.7353, 'f1': 0.355, 'AveragePrecision': 0.4795}]   \n",
      "epoch 14: 100%|██████████| 94/94 [00:01<00:00, 91.28it/s, loss=0.461, metrics={'AUROC': 0.7345, 'f1': 0.3445, 'AveragePrecision': 0.4755}] \n",
      "epoch 15: 100%|██████████| 94/94 [00:01<00:00, 90.73it/s, loss=0.459, metrics={'AUROC': 0.7369, 'f1': 0.3571, 'AveragePrecision': 0.4823}] \n",
      "epoch 16: 100%|██████████| 94/94 [00:01<00:00, 92.32it/s, loss=0.46, metrics={'AUROC': 0.7364, 'f1': 0.3492, 'AveragePrecision': 0.4794}]  \n",
      "epoch 17: 100%|██████████| 94/94 [00:01<00:00, 92.16it/s, loss=0.457, metrics={'AUROC': 0.7399, 'f1': 0.3554, 'AveragePrecision': 0.4876}] \n",
      "epoch 18: 100%|██████████| 94/94 [00:01<00:00, 88.17it/s, loss=0.457, metrics={'AUROC': 0.7395, 'f1': 0.3623, 'AveragePrecision': 0.4859}] \n",
      "epoch 19: 100%|██████████| 94/94 [00:01<00:00, 89.51it/s, loss=0.457, metrics={'AUROC': 0.7412, 'f1': 0.366, 'AveragePrecision': 0.4884}]  \n",
      "epoch 20: 100%|██████████| 94/94 [00:01<00:00, 88.26it/s, loss=0.456, metrics={'AUROC': 0.7431, 'f1': 0.358, 'AveragePrecision': 0.4888}]  \n",
      "epoch 21: 100%|██████████| 94/94 [00:01<00:00, 89.21it/s, loss=0.455, metrics={'AUROC': 0.7442, 'f1': 0.3603, 'AveragePrecision': 0.4918}] \n",
      "epoch 22: 100%|██████████| 94/94 [00:01<00:00, 91.53it/s, loss=0.453, metrics={'AUROC': 0.7481, 'f1': 0.3646, 'AveragePrecision': 0.4963}] \n",
      "epoch 23: 100%|██████████| 94/94 [00:01<00:00, 85.68it/s, loss=0.453, metrics={'AUROC': 0.747, 'f1': 0.3594, 'AveragePrecision': 0.4984}]  \n",
      "epoch 24: 100%|██████████| 94/94 [00:01<00:00, 89.78it/s, loss=0.453, metrics={'AUROC': 0.748, 'f1': 0.3673, 'AveragePrecision': 0.5006}]  \n",
      "epoch 25: 100%|██████████| 94/94 [00:01<00:00, 89.86it/s, loss=0.454, metrics={'AUROC': 0.7467, 'f1': 0.3623, 'AveragePrecision': 0.4986}] \n",
      "epoch 26: 100%|██████████| 94/94 [00:01<00:00, 89.81it/s, loss=0.451, metrics={'AUROC': 0.7498, 'f1': 0.3749, 'AveragePrecision': 0.5043}] \n",
      "epoch 27: 100%|██████████| 94/94 [00:01<00:00, 87.62it/s, loss=0.451, metrics={'AUROC': 0.7499, 'f1': 0.369, 'AveragePrecision': 0.5019}]  \n",
      "epoch 28: 100%|██████████| 94/94 [00:01<00:00, 90.54it/s, loss=0.449, metrics={'AUROC': 0.7538, 'f1': 0.3726, 'AveragePrecision': 0.5082}] \n",
      "epoch 29: 100%|██████████| 94/94 [00:01<00:00, 92.67it/s, loss=0.448, metrics={'AUROC': 0.7547, 'f1': 0.3785, 'AveragePrecision': 0.5139}] \n",
      "epoch 30: 100%|██████████| 94/94 [00:01<00:00, 90.11it/s, loss=0.448, metrics={'AUROC': 0.7563, 'f1': 0.3767, 'AveragePrecision': 0.5111}] \n"
     ]
    }
   ],
   "source": [
    "# train and validate\n",
    "trainer = Trainer(model, objective=\"binary\", metrics=[AUROC, F1Score, AveragePrecision])\n",
    "trainer.fit(\n",
    "    X_tab=X_tab,\n",
    "    target=target,\n",
    "    n_epochs=30,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 24/24 [00:00<00:00, 41.27it/s]\n",
      "predict: 100%|██████████| 24/24 [00:00<00:00, 41.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# predict on test\n",
    "X_tab_te = tab_preprocessor.transform(df_test)\n",
    "preds = trainer.predict(X_tab=X_tab_te)\n",
    "pred_probs = trainer.predict_proba(X_tab=X_tab_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC:0.7325470171931387\n",
      "PrecisionRecall-AUC:0.47830503173589833\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "target = \"default.payment.next.month\"\n",
    "y = df_test[target].values\n",
    "print(\"ROC-AUC:{}\".format(roc_auc_score(y, pred_probs[:, 1])))\n",
    "print(\"PrecisionRecall-AUC:{}\".format(average_precision_score(y, pred_probs[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['emb_0', 'emb_1', 'emb_2', 'emb_3', 'emb_4', 'emb_5', 'emb_6', 'emb_7', 'emb_8', 'emb_9', 'emb_10', 'emb_11', 'emb_12', 'emb_13', 'emb_14', 'emb_15', 'emb_16', 'emb_17'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_wide \u001b[39m=\u001b[39m wide_preprocessor\u001b[39m.\u001b[39mfit_transform(df_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tab_preprocessor \u001b[39m=\u001b[39m TabPreprocessor(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     cat_embed_cols\u001b[39m=\u001b[39mcat_embed_cols, continuous_cols\u001b[39m=\u001b[39mcontinuous_cols  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_tab \u001b[39m=\u001b[39m tab_preprocessor\u001b[39m.\u001b[39;49mfit_transform(df_train)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:258\u001b[0m, in \u001b[0;36mTabPreprocessor.fit_transform\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, df: pd\u001b[39m.\u001b[39mDataFrame) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m    257\u001b[0m     \u001b[39m\"\"\"Combines ``fit`` and ``transform``\"\"\"\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(df)\u001b[39m.\u001b[39mtransform(df)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:195\u001b[0m, in \u001b[0;36mTabPreprocessor.fit\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_embed_input\u001b[39m.\u001b[39mappend((k, \u001b[39mlen\u001b[39m(v), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim[k]))\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontinuous_cols \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     df_cont \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_continuous(df)\n\u001b[1;32m    196\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscale:\n\u001b[1;32m    197\u001b[0m         df_std \u001b[39m=\u001b[39m df_cont[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstandardize_cols]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:292\u001b[0m, in \u001b[0;36mTabPreprocessor._prepare_continuous\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstandardize_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontinuous_cols\n\u001b[0;32m--> 292\u001b[0m \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49mcopy()[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcontinuous_cols]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['emb_0', 'emb_1', 'emb_2', 'emb_3', 'emb_4', 'emb_5', 'emb_6', 'emb_7', 'emb_8', 'emb_9', 'emb_10', 'emb_11', 'emb_12', 'emb_13', 'emb_14', 'emb_15', 'emb_16', 'emb_17'] not in index\""
     ]
    }
   ],
   "source": [
    "# prepare the data\n",
    "wide_preprocessor = WidePreprocessor(wide_cols=wide_cols)\n",
    "X_wide = wide_preprocessor.fit_transform(df_train)\n",
    "\n",
    "tab_preprocessor = TabPreprocessor(\n",
    "    cat_embed_cols=cat_embed_cols, continuous_cols=continuous_cols  # type: ignore[arg-type]\n",
    ")\n",
    "X_tab = tab_preprocessor.fit_transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TabPreprocessor' object has no attribute 'column_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# build the model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m wide \u001b[39m=\u001b[39m Wide(input_dim\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39munique(X_wide)\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], pred_dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m tab_mlp \u001b[39m=\u001b[39m TabMlp(\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     column_idx\u001b[39m=\u001b[39mtab_preprocessor\u001b[39m.\u001b[39;49mcolumn_idx,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     cat_embed_input\u001b[39m=\u001b[39mtab_preprocessor\u001b[39m.\u001b[39mcat_embed_input,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     continuous_cols\u001b[39m=\u001b[39mcontinuous_cols,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m WideDeep(wide\u001b[39m=\u001b[39mwide, deeptabular\u001b[39m=\u001b[39mtab_mlp)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TabPreprocessor' object has no attribute 'column_idx'"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "wide = Wide(input_dim=np.unique(X_wide).shape[0], pred_dim=1)\n",
    "tab_mlp = TabMlp(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    cat_embed_input=tab_preprocessor.cat_embed_input,\n",
    "    continuous_cols=continuous_cols,\n",
    ")\n",
    "model = WideDeep(wide=wide, deeptabular=tab_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 94/94 [00:00<00:00, 94.59it/s, loss=0.576] \n",
      "/home/vineeth/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pytorch_widedeep/callbacks.py:692: RuntimeWarning: Early stopping conditioned on metric `<class 'torchmetrics.classification.avg_precision.AveragePrecision'>` which is not available. Available metrics are: train_loss\n",
      "  warnings.warn(\n",
      "epoch 2: 100%|██████████| 94/94 [00:01<00:00, 93.93it/s, loss=0.526] \n",
      "epoch 3: 100%|██████████| 94/94 [00:01<00:00, 92.85it/s, loss=0.501] \n",
      "epoch 4: 100%|██████████| 94/94 [00:01<00:00, 93.84it/s, loss=0.486] \n",
      "epoch 5: 100%|██████████| 94/94 [00:01<00:00, 90.87it/s, loss=0.476] \n",
      "epoch 6: 100%|██████████| 94/94 [00:01<00:00, 92.61it/s, loss=0.469] \n",
      "epoch 7: 100%|██████████| 94/94 [00:01<00:00, 91.31it/s, loss=0.465] \n",
      "epoch 8: 100%|██████████| 94/94 [00:01<00:00, 89.69it/s, loss=0.461] \n",
      "epoch 9: 100%|██████████| 94/94 [00:01<00:00, 92.18it/s, loss=0.458] \n",
      "epoch 10: 100%|██████████| 94/94 [00:01<00:00, 88.61it/s, loss=0.455] \n",
      "epoch 11: 100%|██████████| 94/94 [00:01<00:00, 91.49it/s, loss=0.452] \n",
      "epoch 12: 100%|██████████| 94/94 [00:00<00:00, 94.49it/s, loss=0.45]  \n",
      "epoch 13: 100%|██████████| 94/94 [00:00<00:00, 94.19it/s, loss=0.448] \n",
      "epoch 14: 100%|██████████| 94/94 [00:01<00:00, 92.21it/s, loss=0.447] \n",
      "epoch 15: 100%|██████████| 94/94 [00:01<00:00, 90.77it/s, loss=0.445] \n",
      "epoch 16: 100%|██████████| 94/94 [00:00<00:00, 95.86it/s, loss=0.443] \n",
      "epoch 17: 100%|██████████| 94/94 [00:00<00:00, 94.52it/s, loss=0.442] \n",
      "epoch 18: 100%|██████████| 94/94 [00:01<00:00, 93.94it/s, loss=0.44]  \n",
      "epoch 19: 100%|██████████| 94/94 [00:01<00:00, 92.65it/s, loss=0.438] \n",
      "epoch 20: 100%|██████████| 94/94 [00:01<00:00, 92.47it/s, loss=0.438] \n",
      "epoch 21: 100%|██████████| 94/94 [00:01<00:00, 92.53it/s, loss=0.435] \n",
      "epoch 22: 100%|██████████| 94/94 [00:01<00:00, 91.54it/s, loss=0.435] \n",
      "epoch 23: 100%|██████████| 94/94 [00:01<00:00, 89.54it/s, loss=0.434] \n",
      "epoch 24: 100%|██████████| 94/94 [00:01<00:00, 90.87it/s, loss=0.433] \n",
      "epoch 25: 100%|██████████| 94/94 [00:01<00:00, 91.78it/s, loss=0.432] \n",
      "epoch 26: 100%|██████████| 94/94 [00:01<00:00, 90.95it/s, loss=0.43]  \n",
      "epoch 27: 100%|██████████| 94/94 [00:01<00:00, 91.25it/s, loss=0.429] \n",
      "epoch 28: 100%|██████████| 94/94 [00:01<00:00, 92.21it/s, loss=0.429] \n",
      "epoch 29: 100%|██████████| 94/94 [00:00<00:00, 94.86it/s, loss=0.428] \n",
      "epoch 30: 100%|██████████| 94/94 [00:01<00:00, 93.80it/s, loss=0.427] \n"
     ]
    }
   ],
   "source": [
    "# train and validate\n",
    "early_stop_callback = EarlyStopping(monitor=AveragePrecision, \\\n",
    "             min_delta=0.01, patience=3, verbose=False, mode=\"max\")\n",
    "trainer = Trainer(model, objective=\"binary\", accelerator='gpu', max_epochs=30, \\\n",
    "                 min_epochs=1, callbacks=[early_stop_callback])\n",
    "# trainer = Trainer(model, objective=\"binary\", metrics=[AUROC, F1Score, AveragePrecision])\n",
    "trainer.fit(\n",
    "    X_wide=X_wide,\n",
    "    X_tab=X_tab,\n",
    "    target=target,\n",
    "    n_epochs=30,\n",
    "    batch_size=256,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4',\\n       'PAY_5', 'PAY_6'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# predict on test\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_wide_te \u001b[39m=\u001b[39m wide_preprocessor\u001b[39m.\u001b[39;49mtransform(df_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m X_tab_te \u001b[39m=\u001b[39m tab_preprocessor\u001b[39m.\u001b[39mtransform(df_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/vineeth/Documents/LocalWorkspace/DeepAndWide/example_2.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m preds \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mpredict(X_wide\u001b[39m=\u001b[39mX_wide_te, X_tab\u001b[39m=\u001b[39mX_tab_te)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pytorch_widedeep/preprocessing/wide_preprocessor.py:88\u001b[0m, in \u001b[0;36mWidePreprocessor.transform\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Returns the processed dataframe\"\"\"\u001b[39;00m\n\u001b[1;32m     87\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, attributes\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mencoding_dict\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 88\u001b[0m df_wide \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_wide(df)\n\u001b[1;32m     89\u001b[0m encoded \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros([\u001b[39mlen\u001b[39m(df_wide), \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwide_crossed_cols)])\n\u001b[1;32m     90\u001b[0m \u001b[39mfor\u001b[39;00m col_i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwide_crossed_cols):\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pytorch_widedeep/preprocessing/wide_preprocessor.py:138\u001b[0m, in \u001b[0;36mWidePreprocessor._prepare_wide\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mconcat([df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwide_cols], df_cc], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m df\u001b[39m.\u001b[39;49mcopy()[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwide_cols]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_09_2022/lib/python3.9/site-packages/pandas/core/indexes/base.py:5842\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5840\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   5841\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4',\\n       'PAY_5', 'PAY_6'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# predict on test\n",
    "X_wide_te = wide_preprocessor.transform(df_test)\n",
    "X_tab_te = tab_preprocessor.transform(df_test)\n",
    "preds = trainer.predict(X_wide=X_wide_te, X_tab=X_tab_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 24/24 [00:00<00:00, 42.36it/s]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = trainer.predict_proba(X_wide=X_wide_te, X_tab=X_tab_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC:0.7577691069442939\n",
      "PrecisionRecall-AUC:0.5138075451045618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "target = \"default.payment.next.month\"\n",
    "y = df_test[target].values\n",
    "print(\"ROC-AUC:{}\".format(roc_auc_score(y, pred_probs[:, 1])))\n",
    "print(\"PrecisionRecall-AUC:{}\".format(average_precision_score(y, pred_probs[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_widedeep import Tab2Vec\n",
    "t2v = Tab2Vec(model=model, tab_preprocessor=tab_preprocessor)\n",
    "X_vec, y = t2v.transform(df_train, target_col=\"default.payment.next.month\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.0625865 , -0.79887253,  1.4173131 , ..., -0.1364332 ,\n",
       "        -0.18054675,  0.11468483],\n",
       "       [ 0.4391028 ,  0.02701583,  1.4173131 , ...,  0.01621273,\n",
       "        -0.0554886 , -0.16666806],\n",
       "       [-2.0625865 , -0.79887253,  0.5986612 , ..., -0.11623305,\n",
       "        -0.05020997, -0.08599467],\n",
       "       ...,\n",
       "       [-2.0625865 , -0.79887253,  1.4173131 , ...,  0.1665693 ,\n",
       "         0.3082162 ,  0.1384262 ],\n",
       "       [-2.0625865 , -0.79887253,  1.4173131 , ...,  0.48647264,\n",
       "         0.09348635, -0.18639345],\n",
       "       [-2.0625865 , -0.79887253,  0.        , ..., -0.17750688,\n",
       "         0.5486876 , -0.14032812]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec, y = t2v.transform(df_test, target_col=\"income_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9769, 95)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch_09_2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f52ae8a1ae1901b741cf35729be1f81cc1eb44818db4edc8e02098ff6938d29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
