model_parameters:
  model: mlp
  patience: 15 # For early stopping. How many epochs to wait.
  epochs: 100 # number of epochs
  b_sz: 1024 # batch size
  ckpt_path: None # if you want to load the model from a specific checkpoint, supply the path to the checkpoint file
  n_classes: 2 # number of classes
  file_b_sz: 1 # batch size for reading file. Example, file_b_sz=10 means you will read 10 parquet/csv files at one go
  model_storage_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/trained_weights

data_parameters:
  train_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/Dataset/bank/fold1/train # can be a directory or a file
  valid_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/Dataset/bank/fold1/valid # can be a directory or a file
  test_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/Dataset/bank/fold1/test # can be a directory or a file
  extension: csv # data type extension, supports csv and parquet (parquet yet to be implemented)
  num_feat_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/Dataset/bank/numerical_clms.csv # a csv file containing the required features
  categ_feat_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/Dataset/bank/categorical_clms.csv # a csv file containing the required features
  # label_clm: default.payment.next.month
  label_clm: y

execution_parameters:
  is_valid: 0
  report_test: 0
  inference_mode: True # If train mode, set as False, for test mode, set as True

performance_parameters:
  file_workers: 1  # Number of workers for file loading. file_worker = n, implies we will be reading n files in parallel.
  data_workers: 6  # Number of workers for optimizing data loading, etc.