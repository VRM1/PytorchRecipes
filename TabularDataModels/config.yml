model: mlp
patience: 5 # For early stopping. How many epochs to wait.
epochs: 20 # number of epochs
b_sz: 1024 # batch size
file_b_sz: 1 # batch size for reading file. Example, file_b_sz=10 means you will read 10 parquet/csv files at one go
is_valid : 0
report_test: 0
inference_mode: True # If train mode, set as False, for test mode, set as True
train_path: /media/6TB_Volume/DataRepo/LargeSyntheticData/train # can be a directory or a file
valid_path: /media/6TB_Volume/DataRepo/LargeSyntheticData/valid # caan be a directory or a file
test_path: /media/6TB_Volume/DataRepo/LargeSyntheticData/test # can be a directory or a file
extension: parquet # data type extension, supports csv and parquet (parquet yet to be implemented)
n_classes: 2 # number of classes
ckpt_path: None # if you want to load the model from a specific checkpoint, supply the path to the checkpoint file
num_feat_path: /media/6TB_Volume/DataRepo/LargeSyntheticData/numerical_clms.csv # a csv file containing the required features
# categ_feat_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/Dataset/defaultCredit/categorical_clms.csv # a csv file containing the required features
# label_clm: default.payment.next.month
label_clm: label
model_storage_path: /home/vineeth/Documents/GitWorkSpace/PytorchRecipes/TabularDataModels/trained_weights